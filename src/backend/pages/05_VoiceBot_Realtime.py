"""
GPT-4o Realtime Preview Voice Bot with WebRTC Integration
========================================================

This module implements a real-time voice assistant using Azure OpenAI's GPT-4o 
Realtime API with WebRTC for low-latency audio streaming. It provides a 
sophisticated voice interface with real-time conversation capabilities.

Features:
- Real-time audio streaming via WebRTC
- GPT-4o Realtime Preview model integration  
- Low-latency voice interactions
- Conversation persistence with Cosmos DB
- Customizable voice settings and instructions
- Session management and conversation history
"""

import os
import hashlib
import logging
import asyncio
import threading
import queue
import json
import base64

import streamlit as st
import websockets
import av
from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase

# Define a minimal RealtimeConfig class if not imported from elsewhere
class RealtimeConfig:
    def __init__(self, voice, instructions, turn_detection=None):
        self.voice = voice
        self.instructions = instructions
        self.turn_detection = turn_detection

st.set_page_config(page_title="GPT-4o Realtime Voice", layout="wide")
st.title("üé§ GPT-4o Realtime Voice Chat")

# Sidebar for voice settings
with st.sidebar:
    st.header("üîä Voice Settings")
    voices = ["alloy","ash","ballad","coral","echo","fable","nova","onyx","sage","shimmer"]
    selected_voice = st.selectbox("Voice", voices, index=voices.index("shimmer"))
    instructions = st.text_area("Assistant Instructions", "You are a helpful voice assistant.", height=80)
    vad_threshold = st.slider("Voice Activity Detection Threshold", min_value=0.0, max_value=1.0, value=0.5, step=0.01)
    silence_duration = st.slider("Silence Duration (ms)", min_value=100, max_value=2000, value=800, step=50)

# Build config and start WebRTC
config = RealtimeConfig(voice=selected_voice, instructions=instructions)
# Define a minimal RealtimeAudioProcessor if not imported from elsewhere
class RealtimeAudioProcessor(AudioProcessorBase):
    def __init__(self, config):
        super().__init__()
        self.config = config
        # Add any necessary initialization here

    def recv(self, frame: av.AudioFrame) -> av.AudioFrame:
        """Receive and return audio frame (echo)."""
        return frame

def audio_factory():
    return RealtimeAudioProcessor(config)

webrtc_ctx = webrtc_streamer(
    key="realtime-voice",
    mode=WebRtcMode.SENDRECV,
    audio_processor_factory=audio_factory,
    rtc_configuration={"iceServers":[{"urls":["stun:stun.l.google.com:19302"]}]},
    media_stream_constraints={"audio":True, "video":False},
    async_processing=True
)

if webrtc_ctx and webrtc_ctx.state.playing:
    st.success("üü¢ Connected ‚Äì Speak now!")
else:
    st.warning("üî¥ Disconnected ‚Äì click START above to begin")

# Main Content Area
col1, col2 = st.columns([2, 1])

with col1:
    st.header("üéôÔ∏è Real-Time Voice Chat")
    
    # Create Realtime configuration
    config = RealtimeConfig(
        voice=selected_voice,
        instructions=instructions,
        turn_detection={
            "type": "server_vad",
            "threshold": vad_threshold,
            "prefix_padding_ms": 300,
            "silence_duration_ms": silence_duration
        }
    )
    
    # Initialize WebRTC streamer
    if "webrtc_ctx" not in st.session_state:
        def audio_processor_factory():
            return RealtimeAudioProcessor(config)
        
        # RTC Configuration for better connectivity
        rtc_configuration = {
            "iceServers": [
                {"urls": ["stun:stun.l.google.com:19302"]},
                {"urls": ["stun:stun1.l.google.com:19302"]},
            ]
        }
        
        webrtc_ctx = webrtc_streamer(
            key="realtime-voice-chat",
            mode=WebRtcMode.SENDRECV,
            audio_processor_factory=audio_processor_factory,
            rtc_configuration=rtc_configuration,
            media_stream_constraints={
                "video": False,
                "audio": {
                    "sampleRate": 24000,
                    "channelCount": 1,
                    "echoCancellation": True,
                    "noiseSuppression": True,
                    "autoGainControl": True,
                }
            },
            async_processing=True,
        )
        st.session_state.webrtc_ctx = webrtc_ctx
    else:
        webrtc_ctx = st.session_state.webrtc_ctx
    
    # Status indicators
    if webrtc_ctx.state.playing:
        st.success("üü¢ **Connected** - You can start speaking!")
        st.info("üí° The AI will respond automatically when you finish speaking.")
    else:
        st.warning("üî¥ **Disconnected** - Click 'START' to begin voice chat")
        st.info("üéØ Click the START button above to begin your real-time conversation with GPT-4o.")
        
        # Show WebRTC state for debugging
        if webrtc_ctx:
            with st.expander("üîß Connection Debug Info"):
                st.write(f"**WebRTC State:** {webrtc_ctx.state}")
                if hasattr(webrtc_ctx.state, 'signalling_state'):
                    st.write(f"**Signaling State:** {webrtc_ctx.state.signalling_state}")
                if hasattr(webrtc_ctx.state, 'ice_connection_state'):
                    st.write(f"**ICE Connection State:** {webrtc_ctx.state.ice_connection_state}")
                st.write("If connection fails, try refreshing the page or check your microphone permissions.")

with col2:
    st.header("üìä Session Info")
    
    # Connection status
    if webrtc_ctx and webrtc_ctx.state.playing:
        st.metric("Status", "üü¢ Active", "Real-time connection established")
    else:
        st.metric("Status", "üî¥ Inactive", "No connection")
    
    # Audio processor info
    if webrtc_ctx and webrtc_ctx.audio_processor:
        processor = webrtc_ctx.audio_processor
        if hasattr(processor, 'session_active'):
            st.metric("API Connection", 
                     "üü¢ Connected" if processor.session_active else "üî¥ Disconnected",
                     "WebSocket to Azure OpenAI")
    
    # Model information
    # Define model deployment and API version if not already set
    REALTIME_MODEL_DEPLOYMENT = "gpt-4o-realtime-preview"
    REALTIME_API_VERSION = "2024-05-01-preview"
    st.info(f"""
    **Model:** {REALTIME_MODEL_DEPLOYMENT}  
    **API Version:** {REALTIME_API_VERSION}  
    **Voice:** {selected_voice}  
    **Format:** PCM16, 24kHz, Mono
    """)

# Instructions and Help
st.markdown("---")
st.header("üöÄ How to Use")

st.markdown("""
1. **Click START** above to begin the real-time voice session
2. **Start speaking** - the AI will listen continuously  
3. **Pause naturally** - the AI will respond when you finish speaking
4. **Have a conversation** - responses are generated in real-time
5. **Click STOP** to end the session

### üéØ Features
- **Ultra-low latency** voice interactions via WebRTC
- **Natural conversation flow** with voice activity detection  
- **Real-time audio processing** with Azure OpenAI GPT-4o
- **Conversation history** automatically saved to Cosmos DB
- **Customizable voice** and personality settings

### üîß Troubleshooting
- **No audio?** Check your microphone permissions
- **Connection issues?** Refresh the page and try again
- **Poor quality?** Adjust the voice detection sensitivity in settings
""")

# Display recent conversation history if available
if "conversation_doc" in st.session_state:
    with st.expander("üìú Conversation History"):
        conv_doc = st.session_state.conversation_doc
        messages = conv_doc.get('messages', [])
        
        if messages:
            for msg in messages[-10:]:  # Show last 10 messages
                role = msg.get('role', 'unknown')
                content = msg.get('content', '')
                timestamp = msg.get('timestamp', '')
                
                if role == 'user':
                    st.markdown(f"**üó£Ô∏è You** _{timestamp}_: {content}")
                elif role == 'assistant':
                    st.markdown(f"**ü§ñ Assistant** _{timestamp}_: {content}")
        else:
            st.write("No conversation history yet. Start chatting to see messages here!")