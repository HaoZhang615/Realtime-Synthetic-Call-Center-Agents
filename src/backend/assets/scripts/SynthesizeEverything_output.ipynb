{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f0e8f2d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Notebook to synthesize data needed for CosmosDB and Frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4bca17",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "from azure.cosmos import CosmosClient, PartitionKey, exceptions\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "# load the environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d3b5d6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "running_in_docker = os.getenv('RUNNING_IN_DOCKER') == 'true'\n",
    "\n",
    "if running_in_docker:\n",
    "    base_dir = os.path.join(os.getcwd(), \"assets\", \"scripts\")  # Docker environment\n",
    "else:\n",
    "    base_dir = r\"c:\\repo\\AOAI_ContactCenterDemo\\frontend\\assets\\scripts\"  # Local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86e5269",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 0. (Optional) clean up the existing JSON files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc8e1ef",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete all json files in the assets folder recursively\n",
    "def delete_json_files():\n",
    "    assets_dir = os.path.join(base_dir, \"..\", \"..\", \"assets\")\n",
    "    # Walk through the directory and delete JSON files\n",
    "    for root, dirs, files in os.walk(assets_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted: {file_path}\")  # Optional: Print out deleted file paths for confirmation\n",
    "\n",
    "delete_json_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0364b5c1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f03a09",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.1. Configure Azure OpenAI connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b152e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Azure OpenAI configurations\n",
    "api_base = os.getenv(\"AOAI_API_BASE\") # your endpoint should look like the following https://YOUR_RESOURCE_NAME.openai.azure.com/\n",
    "api_key = os.getenv(\"AOAI_API_KEY\")\n",
    "gpt4omini = os.getenv(\"AOAI_GPT4O_MINI_MODEL\")\n",
    "api_version = os.getenv(\"AOAI_API_VERSION\") # this might change in the future 2023-12-01-preview 2024-02-15-preview\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=api_key,  \n",
    "    api_version=api_version,\n",
    "    azure_endpoint = api_base,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bc8c72",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.2. Configure Azure CosmosDB connection and delete existing data of all collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68974466",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Azure Cosmos DB connection details\n",
    "credential = DefaultAzureCredential()\n",
    "cosmos_endpoint = os.getenv(\"COSMOS_ENDPOINT\")\n",
    "cosmos_client = CosmosClient(cosmos_endpoint, credential)\n",
    "database_name = os.getenv(\"COSMOS_DATABASE\")\n",
    "database = cosmos_client.create_database_if_not_exists(id=database_name)\n",
    "\n",
    "def container_exists(database, container_name):\n",
    "    try:\n",
    "        container = database.get_container_client(container_name)\n",
    "        # Attempt to read container properties to confirm existence\n",
    "        container.read()\n",
    "        return True, container\n",
    "    except exceptions.CosmosResourceNotFoundError:\n",
    "        return False, None\n",
    "# Function to get the partition key path from the container\n",
    "def get_partition_key_path(container):\n",
    "    container_properties = container.read()\n",
    "    return container_properties['partitionKey']['paths'][0]\n",
    "\n",
    "def delete_all_items(container):\n",
    "    query = \"SELECT * FROM c\"\n",
    "    items = container.query_items(query, enable_cross_partition_query=True)\n",
    "    \n",
    "    for item in items:\n",
    "        # Extract the partition key value from the document\n",
    "        partition_key_value = item.get(get_partition_key_path(container).strip('/'))\n",
    "        container.delete_item(item, partition_key=partition_key_value)\n",
    "    print(f\"All items in container '{container.id}' have been deleted.\")\n",
    "\n",
    "def refresh_container(database, container_name, partition_key_path):\n",
    "    exists, container = container_exists(database, container_name)\n",
    "    \n",
    "    if exists:\n",
    "        print(f\"Container '{container_name}' already exists. Deleting all items...\")\n",
    "        delete_all_items(container)\n",
    "    else:\n",
    "        print(f\"Container '{container_name}' does not exist. Creating new container...\")\n",
    "        container = database.create_container(\n",
    "            id=container_name, \n",
    "            partition_key=PartitionKey(path=partition_key_path),\n",
    "            # offer_throughput=400\n",
    "        )\n",
    "        print(f\"Container '{container_name}' has been created.\")\n",
    "    \n",
    "    return container\n",
    "# create a container for Customer\n",
    "customer_container_name = \"Customer\"\n",
    "refresh_container(database, customer_container_name, \"/customer_id\")\n",
    "customer_container = database.get_container_client(customer_container_name)\n",
    "# create a container for Product\n",
    "product_container_name = \"Product\"\n",
    "refresh_container(database, product_container_name, \"/product_id\")\n",
    "product_container = database.get_container_client(product_container_name)\n",
    "# create a container for Purchases\n",
    "purchases_container_name = \"Purchases\"\n",
    "refresh_container(database, purchases_container_name, \"/customer_id\")\n",
    "purchases_container = database.get_container_client(purchases_container_name)\n",
    "# create a container for the human conversations\n",
    "human_conversations_container_name = \"Human_Conversations\"\n",
    "refresh_container(database, human_conversations_container_name, \"/customer_id\")\n",
    "human_conversations_container = database.get_container_client(human_conversations_container_name)\n",
    "# create a container for the AI conversations. \n",
    "ai_conversations_container_name = \"AI_Conversations\"\n",
    "refresh_container(database, ai_conversations_container_name, \"/customer_id\")\n",
    "ai_conversations_container = database.get_container_client(ai_conversations_container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4cbf04",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.3. Customizable configurations for synthesization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dcbf50",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "company_name = \"Unilever\"\n",
    "number_of_product = 1\n",
    "number_of_customers = 1\n",
    "number_of_human_conversations = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa91799",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "company_name = \"Google\"\n",
    "number_of_customers = 2\n",
    "number_of_product = 4\n",
    "number_of_human_conversations = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7340867",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_purchases = number_of_customers * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c039c78b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.4. list parameters to ground the synthesization process (rather not change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad64330",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# declare the 4 lists with allowed values\n",
    "sentiments_list = ['positive', 'negative', 'neutral', 'mixed', 'content', 'upset', 'angry', 'frustrated', 'happy', 'disappointed', 'confused']\n",
    "topics_list = ['churn', 'assistance', 'support', 'information', 'billing', 'payment', 'account', 'service', 'Quality', 'Sustainability']\n",
    "agent_list = ['adam','betrace','curie','davinci','emil', 'fred']\n",
    "first_name_list = ['Alex','Brian','Chloe','David','Emma','Fiona','George','Hannah','Ian','Julia','Kevin','Lucy','Michael',\n",
    "    'Nicole','Oliver','Paula','Quinn','Rachel','Samuel','Tara','Ursula','Victor','Wendy','Xander','Yvonne','Zachary']\n",
    "last_name_list = [\"Anderson\",  \"Brown\",  \"Clark\",  \"Davis\",  \"Evans\",  \"Foster\",  \"Garcia\",  \"Harris\",  \"Ingram\",  \"Johnson\",  \"King\",  \"Lewis\",  \"Martin\",  \n",
    "                  \"Nelson\",  \"Owens\",  \"Parker\",  \"Quinn\",  \"Robinson\",  \"Smith\",  \"Taylor\",  \"Underwood\",  \"Vargas\",  \"Wilson\",  \"Xavier\",  \"Young\",  \"Zimmerman\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c28222a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3dd6f2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.1. Function to generate list of products and their official websites urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e48b8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to generate a list of products for a given company and the official website url of those products\n",
    "def create_product_and_url_list(company_name, number_of_product, temperature=0.7, max_tokens=200):\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"you are a helpful assistant who helps people\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"generate a json list of {number_of_product} most popular product at brand level of the company {company_name}, and the official website url of those products. \n",
    "            Example for microsoft: Xbox, Surface, Windows, Office, Azure. Example for apple: iPhone, iPad, Mac, Apple Watch, AirPods. Example for Unilever: Dove, Lipton, Hellmann's, Knorr, Ben & Jerry's.\n",
    "            The list contains two keys: 'products' and 'urls'. The 'products' key contains the list of products and the 'urls' key contains the list of urls.\"\"\"\n",
    "        }\n",
    "        ]\n",
    "    openai_output = client.chat.completions.create(\n",
    "      model=gpt4omini,\n",
    "      messages=messages,\n",
    "      temperature= temperature,\n",
    "      max_tokens= max_tokens,\n",
    "      response_format = { \"type\": \"json_object\" }\n",
    "      )\n",
    "    \n",
    "    generated_list = json.loads(openai_output.choices[0].message.content)\n",
    "    file_path = os.path.join(base_dir, \"../Products_and_Urls_List\", f\"{company_name}_products_and_urls.json\")\n",
    "    # save the generated_list as json file to local file folder Products_and_Urls_List. Make sure to write the file in utf-8 encoding\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(generated_list, f, ensure_ascii=False, indent=4)\n",
    "    return generated_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189ce241",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.2. Function to randomly pick a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8323ec92",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to generate random combination of sentiment, topic and product for AOAI to synthesize converstation content.\n",
    "def randomized_prompt_elements(sentiments_list, topics_list, products_list, agend_list, first_name_list):\n",
    "    # Randomly draw an element from the supplied lists for the sentiment, topic, and product \n",
    "    random_sentiment = random.choice(sentiments_list)\n",
    "    random_topic = random.choice(topics_list)\n",
    "    random_product = random.choice(products_list)\n",
    "    random_agent =random.choice(agend_list)\n",
    "    random_customer = random.choice(first_name_list)\n",
    "    \n",
    "    # Return the randomized element string \n",
    "    return random_sentiment, random_topic, random_product, random_agent, random_customer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a3314f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.3. Function to call Azure OpenAI API to synthesize json data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed96da5d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to generate a conversation between a customer and an agent\n",
    "def create_document(document_creation_prompt, temperature=0.9, max_tokens=2000):\n",
    "    # Submit the answer from the QA Bot to the AOAI model for summariation\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"you are a helpful assistant who helps people\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": document_creation_prompt,\n",
    "        }\n",
    "        ]\n",
    "    openai_output = client.chat.completions.create(\n",
    "      model=gpt4omini,\n",
    "      messages=messages,\n",
    "      temperature= temperature,\n",
    "      max_tokens= max_tokens,\n",
    "      response_format = { \"type\": \"json_object\" }\n",
    "      )\n",
    "    \n",
    "    generated_document = openai_output.choices[0].message.content\n",
    "\n",
    "    return generated_document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97594b6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.4. Function to create dynamic json file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3714ff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to create dynamic document name based on the randomized combination of sentiment, topic and product. \n",
    "def create_document_name(i, random_selection1, random_selection2, random_selection3):\n",
    "    # Create a name for the document based on the 3 randomly selected values.\n",
    "    # if the product name has spaces, replace them with underscores\n",
    "    document_name = f\"{i}_{random_selection1.replace(' ', '_')}_{random_selection2.replace(' ', '_')}_{random_selection3.replace(' ', '_')}.json\"\n",
    "    return document_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16e40b7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.5. Function to upload the synthesized local json data to Azure CosmosDB container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a6d68d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get the partition key path from the container\n",
    "def get_partition_key_path(container):\n",
    "    container_properties = container.read()\n",
    "    return container_properties['partitionKey']['paths'][0]\n",
    "\n",
    "# Function to save the JSON files to Azure Cosmos DB\n",
    "def save_json_files_to_cosmos_db(filesfolder, container):\n",
    "    # Get the partition key path for the container\n",
    "    partition_key_path = get_partition_key_path(container).strip('/')  # Remove leading slash\n",
    "\n",
    "    # Get the list of all files in the folder\n",
    "    files = os.listdir(filesfolder)\n",
    "    for file in files:\n",
    "        with open(f'{filesfolder}/{file}', 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            item_id = data.get('id')\n",
    "            if item_id:\n",
    "                # Extract the partition key value from the document\n",
    "                partition_key_value = data.get(partition_key_path)\n",
    "\n",
    "                if partition_key_value:\n",
    "                    try:\n",
    "                        # Read the item from Cosmos DB\n",
    "                        existing_item = container.read_item(item=item_id, partition_key=partition_key_value)\n",
    "                        # Replace the existing item\n",
    "                        container.replace_item(item=item_id, body=data)\n",
    "                        print(f\"Document {file} has been successfully updated in Azure Cosmos DB!\")\n",
    "                    except exceptions.CosmosResourceNotFoundError:\n",
    "                        # Item not found, so create a new one\n",
    "                        container.create_item(body=data)\n",
    "                        print(f\"Document {file} has been successfully created in Azure Cosmos DB!\")\n",
    "                else:\n",
    "                    print(f\"Document {file} is missing the partition key value.\")\n",
    "            else:\n",
    "                # Create a new item if `id` is not provided\n",
    "                container.create_item(body=data)\n",
    "                print(f\"Document {file} has been successfully created in Azure Cosmos DB!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8633cb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.6. Function to synthesize a list of customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e47edc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# funtion to generate synthetic conversations between customer and agent for the Call Center Demo and save them as JSON files in the local folder synthesized_documents\n",
    "def synthesize_customer_profiles(number_of_customers):\n",
    "    for i in range(number_of_customers):# the range number decides how many files/synthetic customer profiles, which should be generated in a randomized manner. \n",
    "        # parameterized prompt generation\n",
    "        random_firstname = random.choice(first_name_list)\n",
    "        random_lastname = random.choice(last_name_list)\n",
    "        document_creation_prompt = f\"\"\"CREATE a JSON document of a customer profile whose first name is {random_firstname} and last name is {random_lastname}. \n",
    "        The required schema for the document is to follow the example below:\n",
    "        {{\n",
    "            \"first_name\": \"Alex\",\n",
    "            \"last_name\": \"Richardson\",\n",
    "            \"email\": \"alex.richardson@example.com\",\n",
    "            \"address\": {{\n",
    "                \"street\": \"Fourth St 19\",\n",
    "                \"city\": \"Chicago\",\n",
    "                \"postal_code\": \"60601\",\n",
    "                \"country\": \"USA\"\n",
    "            }},\n",
    "            \"phone_number\": \"+17845403125\"\n",
    "        }}\n",
    "        Be creative about the values and do not use markdown to format the json object.\n",
    "    \"\"\"\n",
    "\n",
    "        generated_document = create_document(document_creation_prompt)\n",
    "        document_name = create_document_name(i, random_firstname, random_lastname, \"\")\n",
    "\n",
    "        # Save the JSON document to the local folder Cosmos_Customer\n",
    "        file_path = os.path.join(base_dir, \"../Cosmos_Customer\", document_name)\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(generated_document)\n",
    "        print(f\"Document {document_name} has been successfully created!\")\n",
    "        # time.sleep(1) # sleep for 5 second to avoid rate limiting\n",
    "    # loop through the files in the local folder Cosmos_Customer and update them:\n",
    "    # 1. read the file and load the content\n",
    "    # 2. create a hash value of the combination of first_name and last_name and assign it to the customer_id\n",
    "    # 3. add a id field with the value of the current iteration index number plus the customer_id\n",
    "    # 4. save the updated content back to the file\n",
    "    directory = os.path.join(base_dir, \"../Cosmos_Customer\")\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            customer_profile = json.load(f)\n",
    "            customer_id = uuid.uuid3(uuid.NAMESPACE_DNS, f\"{customer_profile['first_name']}_{customer_profile['last_name']}\").hex\n",
    "            customer_profile['customer_id'] = customer_id\n",
    "            customer_profile['id'] = f\"{filename.split('_')[0]}_{customer_id}\"\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(customer_profile, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Document {filename} has been successfully updated!\")\n",
    "        # time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e9abcf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.7. Function to synthesize a list of product details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d413d22",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# funtion to generate synthetic conversations between customer and agent for the Call Center Demo and save them as JSON files in the local folder synthesized_documents\n",
    "def synthesize_product_profiles(company_name):\n",
    "    producturls_file_path = os.path.join(base_dir, \"../Products_and_Urls_List\", f\"{company_name}_products_and_urls.json\")\n",
    "    with open(producturls_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        products_list = json.load(f)[\"products\"]\n",
    "    for idx, product in enumerate(products_list):\n",
    "        # parameterized prompt generation\n",
    "        document_creation_prompt = f\"\"\"CREATE a JSON document of a product profile. The product is {product} made by {company_name}. \n",
    "        The required schema for the document is to follow the example below:\n",
    "        {{\n",
    "            \"name\": \"string\", \n",
    "            \"category\": \"string\", \n",
    "            \"type\": \"string\", \n",
    "            \"brand\": \"string\", \n",
    "            \"unit_price\": \"number\",\n",
    "            \"weight\": {{\n",
    "                \"value\": \"number\",\n",
    "                \"unit\": \"string\"\n",
    "            }},\n",
    "            \"color\": \"string\", \n",
    "            \"material\": \"string\",\n",
    "        }}\n",
    "        Be creative about the values and do not use markdown to format the json object. if any field is not applicable, leave it empty.\n",
    "    \"\"\"\n",
    "\n",
    "        generated_document = create_document(document_creation_prompt)\n",
    "        document_name = create_document_name(idx, product, \"\", \"\")\n",
    "        file_path = os.path.join(base_dir, \"../Cosmos_Product\", document_name)\n",
    "        # save the JSON document to the local folder synthesized_documents\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(generated_document)\n",
    "        print(f\"Document {document_name} has been successfully created!\")\n",
    "        #time.sleep(1) # sleep for 5 second to avoid rate limiting\n",
    "    # loop through the files in the local folder Cosmos_Product and update them:\n",
    "    # 1. add a product_id field (hash value based on the current file name) to the content\n",
    "    # 2. add a id field (hash value based on the prefix value of the current file name and the product_id) to the content\n",
    "    # 3. save the updated content back to the file\n",
    "    directory = os.path.join(base_dir, \"../Cosmos_Product\")\n",
    "    for filename in os.listdir(directory):\n",
    "        path = os.path.join(directory, filename)\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            product_profile = json.load(f)\n",
    "            product_id = uuid.uuid3(uuid.NAMESPACE_DNS, f\"{filename}\").hex\n",
    "            product_profile['product_id'] = product_id\n",
    "            product_profile['id'] = f\"{filename.split('_')[0]}_{product_id}\"\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(product_profile, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Document {filename} has been successfully updated!\")\n",
    "        # time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e85d89",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.8. Function to synthesize a randomized list of purchase records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f5f96d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# define function to get today's date as string format MMMM DD, YYYY\n",
    "def get_today_date():\n",
    "    return datetime.today().strftime(\"%B %d, %Y\")\n",
    "# define a function to retrieve a product profile from the Product container of the Cosmos DB based on the product_id\n",
    "def get_product_profile(product_id):\n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        c.name, \n",
    "        c.category, \n",
    "        c.type, \n",
    "        c.brand, \n",
    "        c.unit_price, \n",
    "        c.weight, \n",
    "        c.color, \n",
    "        c.material \n",
    "    FROM c WHERE c.product_id = '{product_id}'\n",
    "    \"\"\"\n",
    "    items = list(product_container.query_items(\n",
    "        query=query,\n",
    "        enable_cross_partition_query=True\n",
    "    ))\n",
    "    return items[0]\n",
    "# funtion to generate synthetic conversations between customer and agent for the Call Center Demo and save them as JSON files in the local folder synthesized_documents\n",
    "def synthesize_purchases():\n",
    "    # loop through the files in the local folder Cosmos_Customer and Cosmos_Product and create a list of customer_ids and product_ids respectively\n",
    "    customer_ids = []\n",
    "    product_ids = []\n",
    "    customer_directory = os.path.join(base_dir, \"../Cosmos_Customer\")\n",
    "    for filename in os.listdir(customer_directory):\n",
    "        customer_file_path = os.path.join(customer_directory, filename)\n",
    "        with open(customer_file_path, 'r', encoding='utf-8') as f:\n",
    "            customer_profile = json.load(f)\n",
    "            customer_ids.append(customer_profile['customer_id'])\n",
    "    product_directory = os.path.join(base_dir, \"../Cosmos_Product\")\n",
    "    for filename in os.listdir(product_directory):\n",
    "        product_file_path = os.path.join(product_directory, filename)\n",
    "        with open(product_file_path, 'r', encoding='utf-8') as f:\n",
    "            product_profile = json.load(f)\n",
    "            product_ids.append(product_profile['product_id'])\n",
    "    # for each customer, generate 2 random purchase records with random product_id\n",
    "    for idx, customer_id in enumerate(customer_ids):\n",
    "        for i in range(2):\n",
    "            random_product_id = random.choice(product_ids)\n",
    "            document_creation_prompt = f\"\"\"CREATE a JSON document of a purchase record. The product_id is {random_product_id} which is bought by the customer_id {customer_id}. \n",
    "            The required schema for the document is to follow the example below:\n",
    "            {{\n",
    "                \"customer_id\": \"string\",\n",
    "                \"product_id\": \"string\",\n",
    "                \"quantity\": \"number\",\n",
    "                \"purchasing_date\": \"datetime\",\n",
    "                \"delivered_date\": \"datetime\"\n",
    "            }}\n",
    "            Do not use markdown to format the json object. if any field is not applicable, leave it empty.\n",
    "            qantity should be a random number between 1 and 10.\n",
    "            Today is {get_today_date()}, the purchasing_date and delivered_date should be within the last 6 months of today's date.\n",
    "        \"\"\"\n",
    "\n",
    "            generated_document = create_document(document_creation_prompt)\n",
    "            document_name = create_document_name(idx*2+i+1, random_product_id, customer_id, \"\")\n",
    "\n",
    "            # save the JSON document to the local folder synthesized_documents\n",
    "            file_path = os.path.join(base_dir, \"../Cosmos_Purchases\", document_name)\n",
    "            with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(generated_document)\n",
    "            print(f\"Document {document_name} has been successfully created!\")\n",
    "            #time.sleep(1)\n",
    "    # loop through the files in the local folder Cosmos_Purchases and update them:\n",
    "    # 1. add a order_number field (hash value based on the current file name) to the content\n",
    "    # 2. add a id field (hash value based on the prefix value of the current file name and the order_number) to the content\n",
    "    # 3. save the updated content back to the file\n",
    "    directory = os.path.join(base_dir, \"../Cosmos_Purchases\")\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            purchase = json.load(f)\n",
    "            order_number = uuid.uuid3(uuid.NAMESPACE_DNS, f\"{filename}\").hex\n",
    "            purchase['order_number'] = order_number\n",
    "            purchase['product_details'] = get_product_profile(purchase['product_id'])\n",
    "            purchase['total_price'] = purchase['product_details']['unit_price'] * purchase['quantity']\n",
    "            purchase['id'] = f\"{filename.split('_')[0]}_{order_number}\"\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(purchase, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Document {filename} has been successfully updated!\")\n",
    "        #time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd6170a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.9. Function to synthesize human conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d9f667",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# funtion to generate synthetic conversations between customer and agent for the Call Center Demo and save them as JSON files in the local folder synthesized_documents\n",
    "def synthesize_human_conversations(number_of_files, company_name):\n",
    "    # product list is defined by the only json file in the local folder Products_and_Urls_List, in the \"product\" key\n",
    "    producturls_file_path = os.path.join(base_dir, \"../Products_and_Urls_List\", f\"{company_name}_products_and_urls.json\")\n",
    "    with open(producturls_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        products_list = json.load(f)[\"products\"]\n",
    "\n",
    "    for i in range(number_of_files):# the range number decides how many files/synthetic conversations should be generated in a randomized manner. \n",
    "        # parameterized prompt generation\n",
    "        random_sentiment, random_topic, random_product, random_agent, random_customer = randomized_prompt_elements(sentiments_list, topics_list, products_list, agent_list, first_name_list)\n",
    "        document_creation_prompt = f\"\"\"CREATE a JSON document with the key: \"customer_id\", \"messages\", \"agent_id\".\n",
    "        The \"messages\" is JSON array containing multi-turn chat conversation representing an exchange between a customer service \n",
    "        agent for the company {company_name} and their customer. The sentiment of the customer must be {random_sentiment} and \n",
    "        the topic of the conversation betweem the agent and customer should center around {random_topic}. The customer must be asking about the product {random_product}.\n",
    "        The agent handling this conversation is named {random_agent}. The name of the customer is {random_customer}. \n",
    "        At the beginning of the converstion, the agent thanks the customer for calling, tells the customer his/her name and asks what the name of the customer is.\n",
    "        The document should have at least 5 back and forth exchanges between the customer and the agent and the length MUST NOT EXCEED 800 words.\n",
    "        The \"customer_id\" should be a number between 1 and 26, based on the first letter of the customer name in the alphabetical sequence, e.g. customer_id for Julia is 10, for Emma is 5. \n",
    "        The \"agent_id\" should be a number between 1 and 6, based on the first letter of the agent name in the alphabetical sequence, e.g. agent_id for adam is 1, for davinci is 4. \n",
    "        Do not use markdown to format the json object.\n",
    "        If you encounter double quotes in any text, use backslach escaping method to ensure the validaty of the JSON output. \n",
    "        Example below:\n",
    "        {{\n",
    "        \"customer_id\": 10,\n",
    "        \"messages\": [\n",
    "            {{\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Hi Julia, this is Adam from the customer service team. I see that your Essenza Mini coffee machine is giving you trouble. I can assist you further with this. Would you prefer to go through some troubleshooting steps together, or should I provide you with the contact details for our customer support to arrange a repair or replacement?\"\n",
    "            }},\n",
    "            {{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Look, I don't have time for troubleshooting steps. Just tell me how I can get this thing fixed or replaced.\"\n",
    "            }},\n",
    "            {{\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"I understand, Jennifer. Since your Essenza Mini is still under the 2-year warranty, we can arrange a repair or replacement for you. I'll need to gather a few details to proceed. \\n\\nCould you please confirm the following:\\n1. The serial number of your coffee machine.\\n2. A brief description of the issue you're experiencing.\\n\\nOnce I have this information, I'll expedite the process for you.\"\n",
    "            }},\n",
    "            {{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Fine, the serial number is 12345ABC. The machine won’t turn on at all, no matter what I do. Now, can we get this sorted quickly?\"\n",
    "            }},\n",
    "            {{\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Thank you for providing the details, Jennifer. I'll get this sorted for you right away. \\n\\nI'll initiate the repair/replacement process and our customer support team will contact you shortly to arrange the next steps. You should receive an email with further instructions within the next 24 hours.\\n\\nIn the meantime, if there's anything else you need or any other questions you have, feel free to let me know. We're here to help!\"\n",
    "            }},\n",
    "            {{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Alright, I'll keep an eye out for that email. Just make sure it gets done quickly. Thanks.\"\n",
    "            }},\n",
    "            {{\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Absolutely, Jennifer. \"\n",
    "            }},\n",
    "            {{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Yeah, yeah. We'll see.\"\n",
    "            }}\n",
    "        ],\n",
    "        \"agent_id\": 1}}\n",
    "    \"\"\"\n",
    "\n",
    "        generated_document = create_document(document_creation_prompt)\n",
    "        document_name = create_document_name(i, random_sentiment, random_topic, random_product)\n",
    "\n",
    "        # save the JSON document to the local folder synthesized_documents\n",
    "        file_path = os.path.join(base_dir, \"../Cosmos_HumanConversations\", document_name)\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(generated_document)\n",
    "        print(f\"Document {document_name} has been successfully created!\")\n",
    "        # time.sleep(1) # sleep for 5 second to avoid rate limiting\n",
    "    # loop through the files in the local folder Cosmos_HumanConversations and update them:\n",
    "    # 1. read the file and load the content\n",
    "    # 2. create a hash value of the combination of customer_id and agent_id and assign it to the conversation_id\n",
    "    # 3. add a id field with the value of the current iteration index number plus the conversation_id\n",
    "    # 4. save the updated content back to the file\n",
    "    directory = os.path.join(base_dir, \"../Cosmos_HumanConversations\")\n",
    "    for file in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            document = json.load(f)\n",
    "            filename = file.split('.')[0]\n",
    "            # add the \"sentiment\", \"topic\" and \"product\" key based on the file name to each JSON file\n",
    "            sentiment, topic, product = filename.split('_')[1], filename.split('_')[2], filename.split('_')[3]\n",
    "            document[\"sentiment\"] = sentiment\n",
    "            document[\"topic\"] = topic\n",
    "            document[\"product\"] = product\n",
    "            session_id = uuid.uuid3(uuid.NAMESPACE_DNS, f\"{document['customer_id']}_{document['agent_id']}_{document['sentiment']}_{document['topic']}_{document['product']}\").hex\n",
    "            document['session_id'] = session_id\n",
    "            document['id'] = f\"chat_{filename.split('_')[0]}_{session_id}\"\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(document, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Document {file} has been successfully updated!\")\n",
    "        # time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c424289e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Execute the functions to generate the synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9451da73",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.1. Execute the create_product_and_url_list function and review/modify the results\n",
    "#### (recommended but optional) check if the products synthesized make sense and the generated list of urls are correct. Make manual changes directly in the JSON file if needed, which will be the base for the CosmosDB database and Bing Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d064f2b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_product_and_url_list(company_name, number_of_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c517f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.2. Execute the synthesize_customer_profiles function and then upload the synthesized data to CosmosDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c12eda",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "synthesize_customer_profiles(number_of_customers)\n",
    "# upload JSON files from Cosmos_Customer folder to Azure Cosmos DB \n",
    "customer_folder = '../Cosmos_Customer'\n",
    "directory = os.path.join(base_dir, customer_folder)\n",
    "save_json_files_to_cosmos_db(directory, customer_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f69e15",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.3. Execute the synthesize_product_profiles function and then upload the synthesized data to CosmosDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d9a59",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "synthesize_product_profiles(company_name)\n",
    "# upload JSON files from Cosmos_Product folder to Azure Cosmos DB \n",
    "product_folder = '../Cosmos_Product'\n",
    "directory = os.path.join(base_dir, product_folder)\n",
    "save_json_files_to_cosmos_db(directory, product_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6eb989",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.3. Execute the synthesize_purchase function and then upload the synthesized data to CosmosDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b95b4f2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "synthesize_purchases()\n",
    "# upload JSON files from Cosmos_Purchases folder to Azure Cosmos DB \n",
    "purchases_folder = '../Cosmos_Purchases'\n",
    "directory = os.path.join(base_dir, purchases_folder)\n",
    "save_json_files_to_cosmos_db(directory, purchases_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b8193",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.4. Execute the synthesize_human_conversations function and then upload the synthesized data to CosmosDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22bc58",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# execute the synthesize_conversations function\n",
    "synthesize_human_conversations(number_of_human_conversations, company_name)\n",
    "# upload JSON files from Cosmos_HumanConversations folder to Azure Cosmos DB\n",
    "human_conversations_folder = '../Cosmos_HumanConversations'\n",
    "directory = os.path.join(base_dir, human_conversations_folder)\n",
    "save_json_files_to_cosmos_db(directory, human_conversations_container)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 0.013945,
   "end_time": "2025-01-20T22:25:08.411074",
   "environment_variables": {},
   "exception": null,
   "input_path": "./frontend/assets/scripts/SynthesizeEverything.ipynb",
   "output_path": "./frontend/assets/scripts/SynthesizeEverything_output.ipynb",
   "parameters": {
    "company_name": "Google",
    "number_of_customers": 2,
    "number_of_human_conversations": 10,
    "number_of_product": 4
   },
   "start_time": "2025-01-20T22:25:08.397129",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}